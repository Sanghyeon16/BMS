import tensorflow as tf
import numpy as np
import random
import copy
#import os
import matplotlib.pyplot as plt

#%% Data Preprocessing Define

tf.reset_default_graph()
np.random.seed(0)
tf.set_random_seed(777)  # reproducibility

# Tensorboard 파일 저장위치 설정
#LOG_DIR = os.path.join(os.path.dirname(__file__), 'logss')
#if os.path.exists(LOG_DIR) is False:
#    os.mkdir(LOG_DIR)

# -1 ~ 1 범위로 정규화
def MinMaxScalerbyRow(data):
    numerator = data - np.min(data, 0)
    denominator = (np.max(data, 0) - np.min(data, 0)) * 0.5
    return ((numerator) / (denominator + 1e-7)) - 1 # (1e-7: noise를 추가하여 분모가 0이 되는 것을 방지)
    
# 마지막열을 추가하고 그 열에 P=V*I 값 저장
def power_append(xy):
    xy = np.c_[xy, np.zeros(int(len(xy)))]
    for i in range(int(len(xy))):
        xy[i][3] = xy[i][0]*xy[i][1]
    return xy    
    
# 3.2V 이하가 되면 3.2V 이하가 된 시점부터 sec초 시간범위의 NG label 값을 1로 설정
def labeling(xy, sec):
    xy = np.c_[xy, np.zeros(int(len(xy)))]    
    for i in range(int(len(xy))):
        if (i >= sec):
            xy[i][4] = 0
            if(xy[i][0] <= 3.2):
                i = i - sec
                xy[i][4] = 1
                for k in range(sec) :
                    i = i + 1
                    xy[i][4] = 1
    return xy
    
# 데이터의 전압 값을 0 ~ 1 범위로 정규화 후, 최소전압 ~ 최대전압 범위로 다시 정규화
def VoltageMinMax(data, max_val, min_val):
    datav = data[:, 0:1]
    numerator = datav - np.min(datav,0)
    denominator = np.max(datav, 0) - np.min(datav, 0)
    datanv = numerator / (denominator + 1e-7)
    data[:, 0:1] = (datanv * (max_val - min_val)) + min_val
    return data
    
# 전압 레이블을 이전과 현재의 전압의 차이인 Vd로 변경하여 데이터의 레이블을 다음과 같이 설정. (Vd, I, T, P)
def chage_toVdelta(Xdata): 
    for i in range(int(len(Xdata)) - 1):
        Xdata[i][0] = (Xdata[i + 1][0] - Xdata[i][0])
    Xdata[i + 1][0] = Xdata[i][0]
    return Xdata
    
# 데이터의 레이블을 다음과 같이 설정. (Vd, V, I, T, P) 
def add_Vdelta(Xdata):
    delta_data = np.zeros((int(len(Xdata)), 1))
    delta_data = Xdata.copy()
    delta_data = np.insert(delta_data, 0, 0, axis=1)
    for i in range(int(len(Xdata)) - 1):
        delta_data[i][0] = (Xdata[i + 1][0] - Xdata[i][0])
    delta_data[i + 1][0] = delta_data[i][0]
    return delta_data
    
# 전류 값 반올림
def rounding(Xdata):
    for i in range(int(len(Xdata))):
        Xdata[i][1] = round(Xdata[i][1],2) # I
    return Xdata
    
# 데이터의 열 삭제    
def erasing(Xdata): #Vd Vm Irn Tn Pn
    data4X = np.delete(Xdata, 4, axis = 1)
    return np.delete(data4X, 3, axis = 1)
    #return np.delete(data3X, 2, axis = 1)
    #return np.delete(data2X, 0, axis = 1)
    
# NG 값이 1인 갯수, NG 값이 0인 갯수 반환. data_dim(데이터의 열 수)
def NG_count(xy, data_dim):
    j = 0
    for i in range(int(len(xy))):
        if (xy[i][data_dim] == 1):
            j = j + 1
    return j, int(len(xy)) - j 
    
# 2차원의 데이터를 seq_length 크기만큼 분할하고 분할한 것들을 하나씩 쌓아 올려 3차원 데이터 생성
def build_dataset(time_series, seq_length, data_dim):
    dataX = []
    dataY = []
    for i in range(0, len(time_series) - seq_length):
        _x = time_series[i:i + seq_length, 0:data_dim]
        _y = time_series[i + seq_length - 1, [-1]]
        #print(_x, "->", _y)
        dataX.append(_x)
        dataY.append(_y)
    return np.array(dataX), np.array(dataY)
    
# NG 값이 0인 데이터와 NG 값이 1인 데이터의 비율을 1:1 로 맞춘다.
def balancing(Xdata, Ydata, Max):    
    databX = []
    databY = []
    j = 0
    k = 0
    leng = int(len(Ydata))
    randomRow = np.arange(leng) 
    random.shuffle(randomRow) # shuffle
    for i in randomRow:
        # 임의의 순번 중 NG가 0인 순번의 데이터를 NG1인 데이터의 수만큼 새롭게 쌓는다.
        if Ydata[randomRow[i]] == 0:   
            if j < Max: 
                _x1 = Xdata[randomRow[i],:]
                _y1 = Ydata[randomRow[i],:]
                databX.append(_x1)
                databY.append(_y1)
                j = j + 1
        else: 
            if k < Max:
                _x2 = Xdata[randomRow[i],:]
                _y2 = Ydata[randomRow[i],:]
                databX.append(_x2)
                databY.append(_y2)
                k = k + 1
        if j >= Max and k >= Max:
            break
            
    return np.array(databX), np.array(databY)
    
# 데이터 병합
def combine(xy1_x, xy1_y, xy2_x, xy2_y):
    dataX = np.vstack([np.array(xy1_x), np.array(xy2_x)])
    dataY = np.vstack([np.array(xy1_y), np.array(xy2_y)])
    
    return dataX, dataY
    
# 데이터 스케일링(전류, 온도, 전력 정규화)
def Scaling_dataset(dataX): # dataX(7000,100,4)
    for i in range(dataX.shape[0]):
        dataX[i,:,2:5] = MinMaxScalerbyRow(dataX[i,:,2:5])
    return dataX  
    
# 기존의 데이터의 값들을 무작위로 섞어 재배열
def shuffle_dataset(dataX,dataY):
    shuffle = np.arange(dataY.shape[0])
    np.random.shuffle(shuffle)
    datasX = dataX[shuffle]
    datasY = dataY[shuffle]
    return datasX, datasY
    
# leng 크기만큼 샘플 크기를 줄임
def sampleSizeDown(data, div):
    datad = []
    
    for i in range(0, int(len(data)/div)):#int(len(data)/div)):
        _d = data[i, :]
        datad.append(_d)
        
    return np.array(datad)
    
# 데이터를 3등분하여 반환
def sampledivide(Xdata, Ydata):
    data1X = []
    data2X = []
    data3X = []
    data1Y = []
    data2Y = []
    data3Y = []
    leng = int(len(Ydata) / 3)
    for i in range(0, leng * 3):
        if i < leng:
            _1x = Xdata[i, :, :]
            _1y = Ydata[i, :]
            data1X.append(_1x)
            data1Y.append(_1y)
        elif (i >= leng) and (i < (leng * 2)):
            _2x = Xdata[i, :, :]
            _2y = Ydata[i, :]
            data2X.append(_2x)
            data2Y.append(_2y)
        else:
            _3x = Xdata[i, :, :]
            _3y = Ydata[i, :]
            data3X.append(_3x)
            data3Y.append(_3y)
            
    return np.array(data1X), np.array(data1Y), np.array(data2X), np.array(data2Y), np.array(data3X), np.array(data3Y)
    
    
#%% Model Training Function Define

# 모델 전체를 설정하고 모델의 출력(예측결과)을 반환한다.
# 생성한 셀과 입력을 토대로 RNN 구조를 생성한다. 이때, output과 마지막 상태를 반환한다.
# 이때 각 입출력의 데이터 크기는 X[7579,100,5] outputs[7579,100,10] 이고 state는 매 셀마다 넘겨주는 내부 오차 값이다.
def inference(X, seq_length=None, hidden_dim=None, output_dim=None):
    def lstm_cell():
       lstm = tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell(hidden_dim)#rnn.LSTMCell(hidden_dim, forget_bias=1.0)
       return lstm
    multi_cell = tf.contrib.rnn.MultiRNNCell([lstm_cell() for _ in range(5)])#num_LSTM_layers
    #cell = tf.contrib.rnn.LSTMCell(hidden_dim, forget_bias=1.0)
    #multi_cell = tf.contrib.rnn.MultiRNNCell([cell]*5)
    outputs, _states = tf.nn.dynamic_rnn(multi_cell, X, dtype=tf.float32)
    
    #-------1. fully connected method-------
    # hidden dim 크기의 outputs의 차원을 1차원으로 바꿔준다.
    # Fully connected는 마지막 출력을 확률 값으로 변환하여(즉, 모든 출력값을 0~1 사이로 변환하여 전체 합이 1이 되게 한다.)
    # 여러 개의 레이블 중 한 개를 선택한다. 
    # 이렇게 Y_pred [7579, 1] 형태의 예측값이 출력된다.
    Y_pred = tf.contrib.layers.fully_connected(
           outputs[:, -1], output_dim, activation_fn=None)  # We use the last cell's output
    
    #-------2. matmul method-------    
#    def weight_variable(shape):
#        initial = np.sqrt(2.0 / shape[0]) * tf.truncated_normal(shape, stddev=0.01)
#        Weight = tf.Variable(initial, name='w')
#        
#        return Weight
##    def bias_variable(shape):
#        initial = tf.zeros(shape, dtype=tf.float32)
#        Bias = tf.Variable(initial, name='b')
#        
#        return Bias
#    V = weight_variable([hidden_dim, output_dim])
#    c = bias_variable([output_dim])
#    Y_pred = tf.matmul(outputs[:,-1], V) + c
    return Y_pred
    
# 모델의 오차함수를 정의하고 그 값을 반환한다.
# cross_entropy 함수 이용 (예측한 값이 실제 값과 차이가 크면 cost 값이 크게 나타나고 예측한 값이 실제 값과 유사하면 cost 값이 작게 나타난다.) 
# 크로스 엔트로피 함수를 사용한 이유는 Hypothesis 함수가 시그모이드 함수를 거쳐서 0과 1사이의 값을 갖게 되고, 
# cost 함수에 local minima가 생기기 때문에 cost 함수가 log 함수 형태인 크로스엔트로피 함수를 써서 local minima를 없앤다.
# cost 함수의 최솟값을 찾는 것은 오차를 최소화하기 위한 학습이다.
def cost(Y_pred, Y, hypothesis):
    with tf.name_scope('cost'):
        cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))
    #tf.summary.scalar('cross_entropy', cost)
    return cost
    
# 결과값을 0.5를 기준으로 반환한다.
# predicted 반환 (0. 또는 1.) dtype=float32
def predicted(Y_pred,hypothesis):
    predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)
    return predicted
# 출력의 예측값과 실제값을 비교하여 정확도를 반환한다.
# tf.reduce_mean : 예측 성공한 횟수 (1의 개수) / 총 예측한 횟수 

def accuracy(Y_pred, Y, predicted):
    with tf.name_scope('accuracy'):
        accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))
    #tf.summary.scalar('accuracy', accuracy)
    return accuracy
    
# 모델을 학습시키고 학습시킨 결과를 반환한다.
def training(cost):
    with tf.name_scope('train'):
        optimizer = \
            tf.train.AdamOptimizer(learning_rate=0.001, beta1=0.9, beta2=0.999)
        train_step = optimizer.minimize(cost)
    return train_step
    
# patience 만큼 loss가 떨어지는지 지켜보다가 patience 내에 loss가 떨어지지 않으면 earlystopping을 한다.
class EarlyStopping():
    def __init__(self, patience=0, verbose=0):
        self._step = 0
        self._loss = float('inf')
        self.patience = patience
        self.verbose = verbose
    def validate(self, loss):
        if self._loss < loss:
            self._step += 1
            if self._step > self.patience:
                #if self.verbose:
                    #print('early stopping')
                return True
        else:
            self._step = 0
            self._loss = loss
        return False

    
#%%

if __name__ == '__main__':

#Parameters
    #Valuating time period
    seq_length = 150
    
    #Vd: Vm's gradient, Vm: normallized by standard MIXMAX, Irn: I rounded and normalized, Tn: T normalized, Pn: P noramlied
    data_dim = 5 #Vd Vm Irn Tn Pn 
    
    hidden_dim = 15         #RNN outputs which will be choosen by fully connected layer
    output_dim = 1          #Y_pred's dimension
    iterations = 1500       #Number of learning
    
    sec = 180               #Remaining time before 3.2V
    Volt_max = 4.082        #Maximum Value of Voltage
    Volt_min = 3.2          #Minimum Value of Voltage
    downSize_div = 2        #Reducing size when OOM error happens.
    
#Data preprocessing
    #Preprocessing Order: loadtxt, power_append, Labeling -> V,I,T,P
    #   Naming Rule: DataUsage_FileNumber_PrepocessingSteps
    
    #Reference Discharge Dataset [Voltage, Current, Temperture]
    #train_n1_s1 = np.loadtxt('RW25_refdis_1.csv', delimiter=',')
    test_s1 = np.loadtxt('RW25_refdis_2.csv', delimiter=',')
    
    #RandomWalk Charge and Discharge Dataset [Voltage, Current, Temperture]
    train_n1_s1 = np.loadtxt('RW9_RW_1.csv', delimiter=',')
    #test_s1 = np.loadtxt('RW9_RW_2.csv', delimiter=',')
    
    train_n1_s1 = sampleSizeDown(train_n1_s1, downSize_div)
    
    
    train_n1_s2 = power_append(train_n1_s1)     #Number 1 training data, power label appending
    test_s2 = power_append(test_s1)             #Test data, power laberl appending

    train_n1_s3 = labeling(train_n1_s2, sec)    #Number 1 training data, NG label appending
    test_s3 = labeling(test_s2, sec)            #Test data, NG label appending
    
    train_n1_s4 = rounding(train_n1_s3)         #Number 1 training data, I value rounding
    test_s4 = rounding(test_s3)                 #Test data, I value rounding
    
    train_n1_s5 = VoltageMinMax(train_n1_s4, Volt_max, Volt_min)        #Number 1 training data, V value MinMax Scaling
    test_s5 = VoltageMinMax(test_s4, Volt_max, Volt_min)                #Test data, V value MinMax Scaling
    
    train_n1_s6 = add_Vdelta(train_n1_s5)       #Number 1 training data, Vd label Inserting [Vd Vm Ir T P]
    test_s6 = add_Vdelta(test_s5)               #Test data, Vd label Inserting [Vd Vm Ir T P]
    
    """
    #When editing the labels
    #train_n1_s6 = chage_toVdelta(train_n1_s5)  #Number 1 training data, Vm to Vd label changing [Vd Ir T P]
    #test_s6 = chage_toVdelta(test_s5)          #Test data, Vm to Vd label changing [Vd Ir T P]
    
    #train_n1_s6 = erasing(train_n1_s6)         #Number 1 training data, label erasing
    #test_s6 = erasing(test_s6)                 #Test data, label erasing
    """
    
    j1_n1, j0_n1 = NG_count(train_n1_s6, data_dim)      #Number 1 training data, NG label values(1,0) counting
    k1, k0 = NG_count(test_s6, data_dim)                #Test data, NG label values(1,0) counting
    #Input Data labeling Finished
    
    #Training data transformation
    N_train_1 = int(len(train_n1_s6))           #Checking the length of Training data
    train_set_1 = train_n1_s6[0:N_train_1]      #Indexing
    
    train_built_X, train_built_Y = build_dataset(train_set_1, seq_length, data_dim)     #Training Dataset building
    
    train_scaled_X = Scaling_dataset(train_built_X)     #[Ir T P] labels normalizing to [Irn Tn Pn]
    
    #Test data transformation
    N_test = int(len(test_s6))                  #Checking the length of Training data
    test_set = test_s6[0:N_test]                #Indexing
    
    test_built_X, test_built_Y = build_dataset(test_set, seq_length,data_dim)           #Test Dataset building
    test_scaled_X = Scaling_dataset(test_built_X)       #[Ir T P] labels normalizing to [Irn Tn Pn]
    
    #trainbX_1, trainbY_1 = balancing(train1X_1, train1Y_1, j1_1)
    
    """
    #When we combine various dataset 
    #trainc3X, trainc3Y = combine(trainbX_1, trainbY_1,trainbX_3, trainbY_3)
    #trainc5X, trainc5Y = combine(trainc3X, trainc3Y, trainbX_5, trainbY_5)
    #trainc7X, trainc7Y = combine(trainbX_1, trainbY_1, trainbX_7, trainbY_7)
    #trainc9X, trainc9Y = combine(trainc7X, trainc7Y, trainbX_9, trainbY_9)
    #trainc11X, trainc11Y = combine(trainc9X, trainc9Y, trainbX_11, trainbY_11)
    #trainc13X, trainc13Y = combine(trainc7X, trainc7Y, trainbX_13, trainbY_13)
    """
    
    """
    #Training sample sizing down when Out of Memory error occurred
    #traindX, traindY = sampleSizeDown(trainsdX, train1Y_1, downSize)
    """
    #Randomly shuffled tree different Test dataset building
    #   balancing NG value size 1:1('0':'1') and randomly selecting data which has NG value '0'
    #   Shuffling their orders
    test_balanced_X_1, test_balanced_Y_1 = copy.deepcopy(balancing(test_scaled_X, test_built_Y, k1))
    test_balanced_X_2, test_balanced_Y_2 = copy.deepcopy(balancing(test_scaled_X, test_built_Y, k1))
    test_balanced_X_3, test_balanced_Y_3 = copy.deepcopy(balancing(test_scaled_X, test_built_Y, k1))
    testX_1, testY_1 = shuffle_dataset(test_balanced_X_1, test_balanced_Y_1)
    testX_2, testY_2 = shuffle_dataset(test_balanced_X_2, test_balanced_Y_2)
    testX_3, testY_3 = shuffle_dataset(test_balanced_X_3, test_balanced_Y_3)
    
    
    
#Model Architecture Generation
    #Input place holders
    X = tf.placeholder(tf.float32, [None, seq_length, data_dim], name='X')
    Y = tf.placeholder(tf.float32, [None, 1], name='Y')
    
    #LSTM network build
    Y_pred = inference(X, seq_length=seq_length, hidden_dim=hidden_dim,output_dim=output_dim)
    
    #Hypothesis
    hypothesis = tf.sigmoid(Y_pred)
    
    #Cross_entropy
    cost = cost(Y_pred, Y, hypothesis)
    
    #Optimizer
    train = training(cost)
    
    #Accuracy
    predicted = predicted(Y_pred, hypothesis)
    accuracy = accuracy(Y_pred, Y, predicted)

    #RMSE
    targets = tf.placeholder(tf.float32, [None, 1])
    predictions = tf.placeholder(tf.float32, [None, 1])
    rmse = tf.sqrt(tf.reduce_mean(tf.square(targets - predictions)))
    
    #Accuracy_test Parameters initialization
    Absolute_a_1 = []               #Accuracy tested by test dataset no.1
    Absolute_a_1_epoch = 0
    Absolute_a_1_max = 0            #Recording 'epoch' when the Absolute_a has maximum value
    Absolute_a_2 = []
    Absolute_a_2_epoch = 0
    Absolute_a_2_max = 0
    Absolute_a_3 = []
    Absolute_a_3_epoch = 0
    Absolute_a_3_max = 0
    rec_a_1 = []
    rec_c_3 = []    
    #initialization
    init = tf.global_variables_initializer()
    saver = tf.train.Saver() #saver init
    
    #Saving operations
    for op in (X, Y, Y_pred, hypothesis, cost, train, predicted, accuracy, targets, predictions, rmse):
        tf.add_to_collection("my_important_ops", op)
    
    """
    #When we didn't define the operations and testing sess only
    #saver = tf.train.import_meta_graph("./my_model_1.ckpt.meta")    #load meta file of saved model
    #X, Y, Y_pred, hypothesis, cost, train, predicted, accuracy, targets, predictions, rmse = tf.get_collection("my_important_ops")
    """
    
#Training Monitor
    with tf.Session() as sess:

        #"""
        #When we want to monitor the structures and process on Tensorboard
        
        #file_writer = tf.summary.FileWriter(LOG_DIR, sess.graph)
        #merged_summary = tf.summary.merge_all()
        #"""
        
        sess.run(init)      #sess initialization
        
        #Training Start
        for epoch in range(iterations):
            #On each epoch, training data will randomly be set
            train_balanced_X_1, train_balanced_Y_1 = balancing(train_scaled_X, train_built_Y, j1_n1)    
            train_shuffled_X, train_shuffled_Y = shuffle_dataset(train_balanced_X_1,train_balanced_Y_1)
            
            """
            #trainsdX, trainsdY = sampleSizeDown(trainscX, trainY) #when OOM error happens, data size will be reduced
            """
            #Dividing dataset to train all the data (avoiding OOM error)
            train_div1_X, train_div1_Y, train_div2_X, train_div2_Y, train_div3_X, train_div3_Y =  sampledivide(train_shuffled_X, train_shuffled_Y)
            
            #batch theory
            c_1, _ = sess.run([cost, train], feed_dict={
                X: train_div1_X,
                Y: train_div1_Y,
                })
            c_2, _ = sess.run([cost, train], feed_dict={
                X: train_div2_X,
                Y: train_div2_Y,
                })
            a_1, c_3, _ = sess.run([ accuracy, cost, train], feed_dict={
                X: train_div3_X,
                Y: train_div3_Y,
                })
            
            #"""
            #Saving summary as a file to watch on the Tensorboard
            #file_writer.add_summary(summary0, global_step = epoch)
            #"""
            
            rec_a_1.append(a_1)
            rec_c_3.append(c_3)
            
            """"
            #when we use Tensorboard, it will summarlize the records
            #summary = sess.run(merged_summary,feed_dict={X:trainX, Y:trainY})
            """
            
            #The final cost of each epoch is c_3
            print('epoch: ', epoch,' cost_val1: ', 'cost_val1: ', c_1,'cost_val2: ', c_2,'cost_val3: ', c_3, '\naccuracy_val: ', a_1)
            
            #evaluate via No.1 test dataset----------------------------------------------------------
            Absolute_A_1, Absolute_c_1 = sess.run([accuracy, cost], feed_dict={X:testX_1, Y:testY_1})
            _ab_a_1 = Absolute_A_1
            Absolute_a_1.append(_ab_a_1)        #Recording accuracy
            
            print('temp accuracy_test_1: ', Absolute_A_1,' temp cost_test_1: ', Absolute_c_1)
            
            #Saving the sess when Accuracy is higher then the accuracy of previous epoch
            if Absolute_a_1[epoch] >= Absolute_a_1_max:
                Absolute_a_1_max = copy.deepcopy(Absolute_a_1[epoch])
                Absolute_a_1_epoch = copy.deepcopy(epoch)
                save_path = saver.save(sess, "./my_model_RW_1_{}.ckpt".format(epoch))
                
            #evaluate via No.2 test dataset----------------------------------------------------------
            Absolute_A_2, Absolute_c_2= sess.run([accuracy, cost], feed_dict={X:testX_2, Y:testY_2})
            _ab_a_2 = Absolute_A_2
            Absolute_a_2.append(_ab_a_2)

            print('temp accuracy_test_2: ', Absolute_A_2,' temp cost_test_2: ', Absolute_c_2)
            
            #Saving the sess when Accuracy is higher then the accuracy of previous epoch
            if Absolute_a_2[epoch] >= Absolute_a_2_max:
                Absolute_a_2_max = copy.deepcopy(Absolute_a_2[epoch])
                Absolute_a_2_epoch = copy.deepcopy(epoch)
                save_path = saver.save(sess, "./my_model_RW_2_{}.ckpt".format(epoch))   #save first trained model
            
            #evaluate via No.3 test dataset----------------------------------------------------------
            Absolute_A_3, Absolute_c_3= sess.run([accuracy, cost], feed_dict={X:testX_3, Y:testY_3})
            _ab_a_3 = Absolute_A_3
            Absolute_a_3.append(_ab_a_3)

            print('temp accuracy_test_3: ', Absolute_A_3,' temp cost_test_3: ', Absolute_c_3)
            
            #Saving the sess when Accuracy is higher then the accuracy of previous epoch
            if Absolute_a_3[epoch] >= Absolute_a_3_max:
                Absolute_a_3_max = copy.deepcopy(Absolute_a_3[epoch])
                Absolute_a_3_epoch = copy.deepcopy(epoch)
                save_path = saver.save(sess, "./my_model_RW_3_{}.ckpt".format(epoch))  
            
            
            
        #Training Finished and Finding the finest sess
        if Absolute_a_1_max > Absolute_a_2_max and Absolute_a_1_max > Absolute_a_3_max:
            Absolute_a_epoch = Absolute_a_1_epoch
            sess_number = 1
        elif Absolute_a_2_max > Absolute_a_3_max:
            Absolute_a_epoch = Absolute_a_2_epoch
            sess_number = 2
        else:
            Absolute_a_epoch = Absolute_a_3_epoch
            sess_number = 3
        
        #restore the finest sess
        saver.restore(sess, "./my_model_RW_{}_{}.ckpt".format(sess_number ,Absolute_a_epoch))  

        #Evaluating the trained model
        test_predict = sess.run(hypothesis, feed_dict={X: testX_1})
        test_analyze_predict = sess.run(hypothesis, feed_dict={X: test_scaled_X})
        
        rmse_val = sess.run(rmse, feed_dict={
                        targets: testY_1, predictions: test_predict})

        a, c = sess.run([accuracy, cost], feed_dict={X:testX_1,Y:testY_1})
        
        print("\nEpoch: ",Absolute_a_epoch, " cost_val: ", c)
        print("Finanl Accuracy: ",a)
        print("RMSE: {}".format(rmse_val))
        
        
    
        # Plot predictions
        plt.figure(1)
        plt.figure(figsize=(10,10),dpi=200)
        plt.xlim([0, 1500])
        plt.title('Learning record')
        plt.plot(rec_c_3,'-r',label='LOSS_Train')
        plt.plot(rec_a_1,'-b',label='Accuracy_Train')
        plt.plot(Absolute_a_1,'-g',label='Accuracy_Test')
        plt.legend()
        plt.xlabel("epoch")
        plt.ylim([0,1.2])
        plt.ylabel("Loss / Accuracy")
        
        plt.figure(2)
        plt.figure(figsize=(10,10),dpi=200)
        plt.title('Sess Test')
        plt.plot(testY_1,'-b',label='Y')
        plt.plot(test_predict,'-g',label='Y_pred')
        plt.legend()
        plt.xlabel("Test No.")
        plt.ylabel("Good/NG")
        plt.show()
        
        plt.figure(3)
        plt.figure(figsize=(10,10),dpi=200)
        trig = 0
        XXX = np.zeros(len(test_built_Y))
        #plt.xlim([5000, 8000])
        plt.plot(test_built_Y,'-b',linestyle='steps',label='Y')
        for nn in range(len(test_built_Y)):
            if(((test_built_Y[nn,:]) == 1) and trig==0):
                nn = nn - 60
                XXX[nn] = 1
                nn = nn + 120
                XXX[nn] = 1
                trig = 1
        plt.plot(test_analyze_predict,'.g',label='Y_pred')
        plt.plot(XXX,'-.r',label='Thresholds')
        plt.grid()
        plt.show()
